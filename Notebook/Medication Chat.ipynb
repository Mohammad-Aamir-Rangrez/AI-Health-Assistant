{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga8c1nhja4Qy"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: pandas in c:\\users\\mohda\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\mohda\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mohda\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mohda\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sooD64r3bIDJ"
      },
      "outputs": [],
      "source": [
        "# Import pandas for data analysis\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./Data_cleaned_medication_QA_data.csv\", encoding='windows-1252', encoding_errors='replace')\n",
        "df = df[['Question', 'Answer']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eRneQPLAqAJL",
        "outputId": "d1772f7e-8edd-4687-9c1a-c3102e86138e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the signs of a healthy body?</td>\n",
              "      <td>The signs of a healthy body include consistent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can I boost my immune system?</td>\n",
              "      <td>To boost your immune system, focus on a balanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>immune system</td>\n",
              "      <td>The *immune system* is your body's natural def...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is a balanced diet, and how do I follow one?</td>\n",
              "      <td>A **balanced diet** is one that provides your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How much water should I drink daily?</td>\n",
              "      <td>The amount of water you should drink daily dep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0              What are the signs of a healthy body?   \n",
              "1                  How can I boost my immune system?   \n",
              "2                                      immune system   \n",
              "3  What is a balanced diet, and how do I follow one?   \n",
              "4               How much water should I drink daily?   \n",
              "\n",
              "                                              Answer  \n",
              "0  The signs of a healthy body include consistent...  \n",
              "1  To boost your immune system, focus on a balanc...  \n",
              "2  The *immune system* is your body's natural def...  \n",
              "3  A **balanced diet** is one that provides your ...  \n",
              "4  The amount of water you should drink daily dep...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head() #show first five rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4SEkJJHwqBwo",
        "outputId": "7aeec0ad-b51a-44fa-f2e1-5a93b61246d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What are the signs of a healthy body?'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Question[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "qTllg8a-qGXW",
        "outputId": "a6b8bca7-135e-4e26-e0ff-a2a1424bc45c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The signs of a healthy body include\\xa0consistent energy levels\\xa0throughout the day, indicating proper nutrition and rest. You should have a\\xa0strong immune system, with fewer instances of colds or infections.\\xa0Healthy skin, hair, and nails\\xa0are also indicators, as they reflect good internal health. A\\xa0stable weight\\xa0within a normal range for your age and height is another sign. Regular\\xa0digestive health\\xa0and normal bowel movements suggest a well-functioning digestive system. Additionally,\\xa0good sleep quality\\xa0and waking up refreshed are key markers.\\xa0Mental clarity, focus, and emotional stability\\xa0also contribute to overall health. Finally, the ability to engage in\\xa0physical activity\\xa0without excessive fatigue or discomfort is a strong sign of a healthy body.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Answer[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs_qECG1qIW5",
        "outputId": "678a409c-9164-48f4-803e-501d3dff3c96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(690, 2)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape # 690 rows | 2 cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPvkkbdbrNp-",
        "outputId": "938e6a8d-fb4b-4112-9a0e-3139146e56eb"
      },
      "outputs": [],
      "source": [
        "#pip install cleantext uncomment when needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dws3d49Lqv1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mohda\\Documents\\AI Health Assistant\\Notebook\n",
            "Current directory: c:\\Users\\mohda\\Documents\\AI Health Assistant\\Notebook\n",
            "Directory contents: ['Couselling Chat.ipynb', 'Data_cleaned_counsel_QA_data.csv', 'Data_cleaned_medication_QA_data.csv', 'Diabetes Classification.ipynb', 'diabetes.csv', 'logs', 'Medication Chat.ipynb', 'Medicine Classification.ipynb', 'random_forest_model.joblib', 'results']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "print(\"Directory contents:\", os.listdir())\n",
        "\n",
        "\n",
        "import cleantext\n",
        "\n",
        "# Function to clean text data by removing unwanted characters and formatting\n",
        "def clean(textdata):\n",
        "    cleaned_text = []\n",
        "    for i in textdata:\n",
        "        cleaned_text.append(cleantext.clean(str(i), extra_spaces=True, lowercase=True, stopwords=False, stemming=False, numbers=True, punct=True, clean_all = True))\n",
        "\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H1ia-jFqrIsG"
      },
      "outputs": [],
      "source": [
        "# Apply the clean function to the questions and answers columns\n",
        "\n",
        "df.Question = list(clean(df.Question))\n",
        "df.Answer = list(clean(df.Answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HcB15JQirImk"
      },
      "outputs": [],
      "source": [
        "# Save the cleaned data into a new CSV file & save\n",
        "df.to_csv(\"Clean_medication_output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5mkpmueML4"
      },
      "source": [
        "### GPT-2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "QhgGKgZ-rYAY",
        "outputId": "f2334a48-2745-42b5-f5fd-929ca58e1ed6"
      },
      "outputs": [],
      "source": [
        "#pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgGgvCqerk-1",
        "outputId": "e338ee7f-c898-41c4-b1f6-036f115d3735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\mohda\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeiMYkpCrp62",
        "outputId": "e8b0118b-1694-4d9e-d666-e791b083f63f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1024\n"
          ]
        }
      ],
      "source": [
        "# Set the padding token for the tokenizer to be the end-of-sequence token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Maximum sequence length that GPT-2 can handle\n",
        "max_length = tokenizer.model_max_length\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MW5Ad0exrry3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bccc5d67e50e426c9bb4b8abaaff1f7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the cleaned QA dataset as a training set using the 'datasets' library\n",
        "dataset = load_dataset('csv', data_files={'train': 'Clean_medication_output.csv'}, split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "99rfOROKr-M0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0abf532feaff40588757579280718440",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/690 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Function to tokenize questions and answers and prepare them for the model\n",
        "def tokenize_function(examples):\n",
        "  '''1. Combine each question and answer into a single input string\n",
        "     2. Tokenize the combined text using the GPT-2 tokenizer\n",
        "     3. Set the labels to be the same as the input_ids (shifted to predict the next word)\n",
        "     4. Return the tokenized output. '''\n",
        "    \n",
        "  combined_text = [str(q) + \" \" + str(a) for q, a in zip(examples['Question'], examples['Answer'])]\n",
        "  tokenized_output = tokenizer(combined_text, padding='max_length', truncation=True, max_length=128)\n",
        "  # Set the labels to be the same as the input_ids (shifted to predict the next word)\n",
        "  tokenized_output['labels'] = tokenized_output['input_ids'].copy()\n",
        "  \n",
        "  return tokenized_output\n",
        "# Tokenize the entire dataset\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "TQGJ16yJsCBc",
        "outputId": "ec5b1ae4-83c1-4117-95fe-3aae63fc0f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: CPU (CPU)\n",
            "Memory: 6.38 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\mohda\\AppData\\Local\\Temp\\ipykernel_11060\\3319484303.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [261/261 5:59:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=261, training_loss=2.8027467691121886, metrics={'train_runtime': 21627.442, 'train_samples_per_second': 0.096, 'train_steps_per_second': 0.012, 'total_flos': 135218626560000.0, 'train_loss': 2.8027467691121886, 'epoch': 3.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    device_type = \"GPU\"\n",
        "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # GB\n",
        "else:\n",
        "    import psutil\n",
        "    device_name = \"CPU\"\n",
        "    device_type = \"CPU\"\n",
        "    total_memory = psutil.virtual_memory().total / 1e9  # GB\n",
        "\n",
        "print(f\"Device: {device_type} ({device_name})\")\n",
        "print(f\"Memory: {total_memory:.2f} GB\")\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "# Define training arguments for the GPT-2 model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',  # Directory to save model outputs\n",
        "    num_train_epochs=3,  # Train for 50 epochs\n",
        "    fp16 = True,\n",
        "    per_device_train_batch_size=8, # Batch size during training\n",
        "    per_device_eval_batch_size=32,  # Batch size during evaluation\n",
        "    eval_strategy=\"no\", # Evaluation can slow training.\n",
        "    save_strategy=\"epoch\", #Saves checkpoints only once per epoch instead of every few steps\n",
        "    warmup_steps=500,  # Warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,  # Weight decay for regularization\n",
        "    logging_dir='./logs',  # Directory for saving logs\n",
        "    logging_steps=500,  # Log every 10 steps\n",
        "    save_steps=2000,  # Save model checkpoints every 1000 steps\n",
        ")\n",
        "\n",
        "# Trainer class to handle training process\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4UrH8iP0u6Cp"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "trainer.save_model('medication_info_model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhXRJT6jeTuz"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JbMs8UuSu5_R"
      },
      "outputs": [],
      "source": [
        "# Function to generate a response based on a user prompt (testing the model)\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")  # no .to('cuda')\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_length=150,\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsHAT1-uxC4_",
        "outputId": "89b73c5f-0ae9-449d-8eb4-3df1a7c146bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot Response: what is desonide ointment used for the treatment of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a severe case of a\n"
          ]
        }
      ],
      "source": [
        "# Example conversation\n",
        "user_input = \"what is desonide ointment used for\"\n",
        "bot_response = generate_response(user_input)\n",
        "print(\"Bot Response:\", bot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use This for Google Collab file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aP4IEboMxDWG",
        "outputId": "c00d1d74-e389-4de4-a151-d20736b6bccd"
      },
      "outputs": [],
      "source": [
        "# Copying the model to Google Drive (optional)\n",
        "# import shutil\n",
        "\n",
        "# Path to the file in Colab\n",
        "#colab_file_path = '/content/med_info_model/model.safetensors'\n",
        "\n",
        "# Path to your Google Drive\n",
        "# drive_file_path = '/content/drive/MyDrive'\n",
        "\n",
        "# Copy the file\n",
        "# shutil.copy(colab_file_path, drive_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use This for vs code and jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uKYwYe5XyXgx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File copied successfully!\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the source file on your system\n",
        "source_file_path = r'C:\\Users\\mohda\\Documents\\AI Health Assistant\\Notebook\\medication_info_model\\model.safetensors'\n",
        "\n",
        "# Destination folder where you want to copy the file\n",
        "destination_folder = r'C:\\Users\\mohda\\Documents\\AI Health Assistant\\backend\\models\\medication_info'\n",
        "\n",
        "destination_file_path = destination_folder + r'\\model.safetensors'\n",
        "# Copy the fil\n",
        "#;[{}] ea\n",
        "shutil.copy(source_file_path, destination_file_path)\n",
        "\n",
        "print(\"File copied successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
